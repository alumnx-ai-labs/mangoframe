{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c504c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "import pysrt\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 1. Configs\n",
    "# ============================\n",
    "INPUT_FOLDER = r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/Drone Imagery 19th August\"        # folder for input videos\n",
    "UNIQUE_DIR = r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/unique_images\"                      # folder for unique plants\n",
    "OUTPUT_VIDEO_DIR = r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/output_videos\"                # folder for annotated videos\n",
    "CSV_PATH = r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/unique_images/detections.csv\"         # detailed log\n",
    "COUNT_PATH = r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/unique_images/unique_count.txt\"     # summary log\n",
    "TRACKER_CONFIG = \"bytetrack.yaml\"                                                                                 # tracker config file\n",
    "os.makedirs(r\"/content/drive/MyDrive/Data Science/Data/Mango Tree Classifier/output_videos\", exist_ok=True)\n",
    "os.makedirs(UNIQUE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e246c8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. Load YOLO Model\n",
    "# ============================\n",
    "model = YOLO(\"yolov11n_335th_epoch_patience_50_best_mAP50.pt\")   # your trained mango model\n",
    "\n",
    "# ============================\n",
    "# 3. Parse SRT Metadata (FIXED)\n",
    "# ============================\n",
    "def parse_srt(srt_path):\n",
    "    subs = pysrt.open(srt_path)\n",
    "    gps_map = {}\n",
    "    for i, sub in enumerate(subs):\n",
    "        frame_num = i + 1\n",
    "        text = sub.text.strip()\n",
    "\n",
    "        # Regex to capture latitude and longitude\n",
    "        lat_match = re.search(r\"latitude:\\s*([-\\d.]+)\", text)\n",
    "        lon_match = re.search(r\"longitude:\\s*([-\\d.]+)\", text)\n",
    "\n",
    "        if lat_match and lon_match:\n",
    "            lat = float(lat_match.group(1))\n",
    "            lon = float(lon_match.group(1))\n",
    "            gps_map[frame_num] = (lat, lon)\n",
    "        else:\n",
    "            gps_map[frame_num] = (None, None)\n",
    "\n",
    "    return gps_map\n",
    "\n",
    "gps_data = parse_srt(SRT_PATH)\n",
    "\n",
    "# ============================\n",
    "# 4. Process Multiple Videos\n",
    "# ============================\n",
    "video_files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(('.mp4', '.avi', '.mov'))]\n",
    "seen_ids = set()\n",
    "\n",
    "with open(CSV_PATH, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"video_file\", \"frame\", \"track_id\", \"x1\", \"y1\", \"x2\", \"y2\", \"lat\", \"lon\", \"image_path\"])\n",
    "\n",
    "    for video_file in video_files:\n",
    "        print(f\"Processing video: {video_file}\")\n",
    "\n",
    "        VIDEO_PATH = os.path.join(INPUT_FOLDER, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        SRT_PATH = os.path.join(INPUT_FOLDER, f\"{video_name}.SRT\")\n",
    "        OUTPUT_VIDEO = os.path.join(OUTPUT_VIDEO_DIR, f\"{video_name}.mp4\")\n",
    "\n",
    "        # Parse GPS data for this video\n",
    "        if os.path.exists(SRT_PATH):\n",
    "            gps_data = parse_srt(SRT_PATH)\n",
    "        else:\n",
    "            print(f\"Warning: No SRT file found for {video_file}\")\n",
    "            gps_data = {}\n",
    "\n",
    "        # Prepare Video Writer\n",
    "        cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (w, h))\n",
    "\n",
    "        frame_num = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_num += 1\n",
    "\n",
    "            # Run YOLOv8 detection + tracking\n",
    "            results = model.track(frame, persist=True, tracker=TRACKER_CONFIG)\n",
    "\n",
    "            if results and len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "                ids = results[0].boxes.id.cpu().numpy().astype(int) if results[0].boxes.id is not None else []\n",
    "\n",
    "                for box, track_id in zip(boxes, ids):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    lat, lon = gps_data.get(frame_num, (None, None))\n",
    "\n",
    "                    # ============================\n",
    "                    # Draw box + ID + GPS (Yellow, Thick, Visible)\n",
    "                    # ============================\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 4)\n",
    "\n",
    "                    # Track ID label\n",
    "                    label = f\"ID:{track_id}\"\n",
    "                    (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "                    cv2.rectangle(frame, (x1, y1 - th - 6), (x1 + tw + 6, y1), (0, 255, 255), -1)\n",
    "                    cv2.putText(frame, label, (x1 + 3, y1 - 5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "\n",
    "                    # Lat/Lon label (below bounding box)\n",
    "                    if lat is not None and lon is not None:\n",
    "                        gps_label = f\"Lat:{lat:.6f}, Lon:{lon:.6f}\"\n",
    "                        (gtw, gth), _ = cv2.getTextSize(gps_label, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)\n",
    "                        cv2.rectangle(frame, (x1, y2 + 5), (x1 + gtw + 6, y2 + gth + 10), (0, 255, 255), -1)\n",
    "                        cv2.putText(frame, gps_label, (x1 + 3, y2 + gth + 5),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "\n",
    "                    # Save first unique crop\n",
    "                    if track_id not in seen_ids:\n",
    "                        seen_ids.add(track_id)\n",
    "                        crop = frame[y1:y2, x1:x2]\n",
    "                        if lat is not None and lon is not None:\n",
    "                            # Include longitude and latitude in the filename\n",
    "                            img_path = os.path.join(UNIQUE_DIR, f\"plant_{track_id}_lon_{lon}_lat_{lat}.jpg\")\n",
    "                        else:\n",
    "                            img_path = os.path.join(UNIQUE_DIR, f\"plant_{track_id}.jpg\") # Fallback if GPS data is missing\n",
    "                        cv2.imwrite(img_path, crop)\n",
    "                    else:\n",
    "                        img_path = \"\"\n",
    "\n",
    "                    # Log to CSV\n",
    "                    writer.writerow([video_file, frame_num, track_id, x1, y1, x2, y2, lat, lon, img_path])\n",
    "\n",
    "            # Save annotated frame\n",
    "            out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"✅ Completed processing: {video_file}\")\n",
    "\n",
    "# ============================\n",
    "# 5. Save Unique Count\n",
    "# ============================\n",
    "with open(COUNT_PATH, \"w\") as f:\n",
    "    f.write(f\"Total unique plants detected: {len(seen_ids)}\\n\")\n",
    "\n",
    "print(\"✅ Processing complete!\")\n",
    "print(f\"Annotated videos saved in: {OUTPUT_VIDEO_DIR}\")\n",
    "print(f\"Unique Mango Trees saved in: {UNIQUE_DIR}\")\n",
    "print(f\"Detections CSV: {CSV_PATH}\")\n",
    "print(f\"Unique count summary: {COUNT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
